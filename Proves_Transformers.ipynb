{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP5RxAOboIGn0F4P8LAmSKC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManelSoengas/tutorials/blob/main/Proves_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAjKXKetRkhW",
        "outputId": "193f0aeb-eed9-4232-8c64-6c19e6c8cf9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el tokenizer y el modelo asociados al pipeline\n",
        "tokenizer = summarizer.tokenizer\n",
        "model = summarizer.model\n",
        "\n",
        "# Visualizar el máximo de tokens que el modelo puede procesar\n",
        "max_tokens = model.config.max_length\n",
        "print(f\"Máximo de tokens que el modelo puede procesar: {max_tokens}\")\n",
        "\n",
        "\n",
        "# Obtener el máximo de tokens de entrada que el modelo puede procesar\n",
        "max_input_tokens = tokenizer.model_max_length\n",
        "print(f\"Máximo de tokens que el modelo puede procesar como entrada: {max_input_tokens}\")\n",
        "\n",
        "# Texto de ejemplo (puedes cambiarlo por tu texto)\n",
        "text = \"Artificial intelligence is a field of computer science that focuses on creating systems capable of performing tasks that typically require human intelligence...\"\n",
        "\n",
        "# Calcular el número de tokens en el texto\n",
        "num_tokens = len(tokenizer.encode(text))\n",
        "print(f\"Número de tokens en el texto: {num_tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n3yGzeZUDc7",
        "outputId": "8e954043-2adc-4cbc-8941-05b5f4aed06a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Máximo de tokens que el modelo puede procesar: 142\n",
            "Máximo de tokens que el modelo puede procesar como entrada: 1024\n",
            "Número de tokens en el texto: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El pipeline admite: text-generation, sentiment-analysis, Zero-shot classification (podemos especificar las etiquetas de clasificació), fill-mask, ner, question-answering, summarization y translation."
      ],
      "metadata": {
        "id": "EbPOkZi7Vovy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer(\n",
        "    \"\"\"\n",
        "   North Korean troops have been deployed to Russia and are operating in the Kursk border region where Ukrainian troops have a foothold, Nato has said for the first time.\n",
        "The alliance's Secretary General Mark Rutte said he could confirm the deployment after weeks of intelligence reports, following a meeting with South Korean security and defence officials on Monday.\n",
        "The newly installed Nato chief said the deployment represented a \"significant escalation\" and a \"dangerous expansion\" of Russia's war in Ukraine.\n",
        "Last week, President Vladimir Putin refused to deny that North Korean troops had arrived in Russia, following reports that Pyongyang was preparing to send thousands of troops to aid its ally.\n",
        "\"\"\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGAENQdnRr2Z",
        "outputId": "9ad51197-35a2-43ee-d118-fc6bf0e60e13"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 142, but your input_length is only 139. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=69)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' North Korean troops are operating in the Kursk border region where Ukrainian troops have a foothold . Nato Secretary General Mark Rutte said he could confirm the deployment after weeks of intelligence reports . The deployment represents a \"significant escalation\" and a \"dangerous expansion\" of Russia\\'s war in Ukraine .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}